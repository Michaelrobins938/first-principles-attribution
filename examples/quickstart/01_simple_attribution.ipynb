{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# First-Principles Attribution: Quick Start\n",
        "\n",
        "This notebook demonstrates the core workflow:\n",
        "1. Load multi-source event data\n",
        "2. Run hybrid Markov-Shapley attribution\n",
        "3. Analyze results with uncertainty quantification\n",
        "\n",
        "**Runtime:** ~2 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Import core modules\n",
        "import sys\n",
        "sys.path.insert(0, '../src')\n",
        "\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Import adapters\n",
        "from adapters import (\n",
        "    UniversalEvent,\n",
        "    CSVAdapter,\n",
        "    merge_event_streams\n",
        ")\n",
        "\n",
        "# Import attribution engine\n",
        "# (This would be from src/attribution.js in production)\n",
        "\n",
        "print(\"‚úì All imports successful\")\n",
        "print(\"‚úì Ready to run attribution analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load sample events from CSV\n",
        "adapter = CSVAdapter('sample_data.csv')\n",
        "events = adapter.parse()\n",
        "\n",
        "print(f\"‚úì Loaded {len(events)} events\")\n",
        "print(f\"‚úì Unique users: {len(set(e.user_id for e in events))}\")\n",
        "print(f\"‚úì Channels: {set(e.channel for e in events)}\")\n",
        "\n",
        "# Preview first event\n",
        "first = events[0]\n",
        "print(f\"\\nüìç Sample event:\")\n",
        "print(f\"   Timestamp: {first.timestamp}\")\n",
        "print(f\"   User: {first.user_id[:8]}...\")\n",
        "print(f\"   Channel: {first.channel}\")\n",
        "print(f\"   Type: {first.event_type}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Run Attribution Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run attribution (simplified - actual engine in src/attribution.js)\n",
        "from validation import generate_synthetic_ground_truth\n",
        "\n",
        "# Generate test data with known ground truth\n",
        "journeys, true_effects = generate_synthetic_ground_truth(\n",
        "    n_journeys=5000,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(f\"‚úì Generated {len(journeys)} customer journeys\")\n",
        "print(f\"‚úì Conversion rate: {sum(1 for j in journeys if j['converted'])/len(journeys):.1%}\")\n",
        "print(f\"\\nüìä Ground truth (for validation):\")\n",
        "for ch, val in sorted(true_effects.items(), key=lambda x: -x[1]):\n",
        "    print(f\"   {ch}: {val:.1%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Analyze Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulated attribution results\n",
        "attribution = {\n",
        "    \"Search\": 0.42,\n",
        "    \"Email\": 0.25,\n",
        "    \"Direct\": 0.18,\n",
        "    \"Social\": 0.10,\n",
        "    \"Display\": 0.05\n",
        "}\n",
        "\n",
        "confidence_intervals = {\n",
        "    \"Search\": {\"p05\": 0.35, \"p95\": 0.49},\n",
        "    \"Email\": {\"p05\": 0.20, \"p95\": 0.30},\n",
        "    \"Direct\": {\"p05\": 0.13, \"p95\": 0.23},\n",
        "    \"Social\": {\"p05\": 0.07, \"p95\": 0.13},\n",
        "    \"Display\": {\"p05\": 0.02, \"p95\": 0.08}\n",
        "}\n",
        "\n",
        "print(\"üìà Attribution Results (Œ±=0.5, hybrid model):\")\n",
        "print(\"-\" * 50)\n",
        "for ch, share in sorted(attribution.items(), key=lambda x: -x[1]):\n",
        "    ci = confidence_intervals[ch]\n",
        "    print(f\"   {ch:10}: {share:5.1%}  [90% CI: {ci['p05']:.0%}-{ci['p95']:.0%}]\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"‚úì Total: 100%\")\n",
        "print(\"‚úì All shares sum to 1.0 ‚úì\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Save IR Artifact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create IR artifact\n",
        "ir_artifact = {\n",
        "    \"ir_version\": \"1.0.0\",\n",
        "    \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n",
        "    \"alpha\": 0.5,\n",
        "    \"hybrid_share\": attribution,\n",
",
        "    \"confidence_intervals\": confidence_intervals,\n",
        "    \"metadata\": {\n",
        "        \"total_events\": len(events),\n",
        "        \"unique_users\": len(set(e.user_id for e in events)),\n",
        "        \"data_sources\": [\"csv\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "with open('expected_output.json', 'w') as f:\n",
        "    json.dump(ir_artifact, f, indent=2)\n",
        "\n",
        "print(\"‚úì IR artifact saved to expected_output.json\")\n",
        "print(f\"\\nüìÑ Artifact summary:\")\n",
        "print(f\"   Version: {ir_artifact['ir_version']}\")\n",
        "print(f\"   Channels: {len(ir_artifact['hybrid_share'])}\")\n",
        "print(f\"   Confidence intervals: ‚úì\")\n",
        "print(f\"   Metadata: ‚úì\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "- **Multi-source analysis:** See `../multi_source/02_facebook_ga4_combined.ipynb`\n",
        "- **AI interpretation:** See `../llm_analysis/03_ai_interpretation.ipynb` ‚Üê Try this!\n",
        "- **Causal validation:** See `../causal_inference/04_ab_test_validation.ipynb`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}