{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI-Powered Attribution Analysis with LLM Scaffold\n",
        "\n",
        "This notebook demonstrates the **unique differentiator** of this framework:\n",
        "Built-in AI interpretation layer that transforms IR artifacts into human-readable insights.\n",
        "\n",
        "## What Makes This Different\n",
        "\n",
        "| Other Tools | This Framework |\n",
        "|-------------|----------------|\n",
        "| Attribution numbers only | Numbers + AI interpretation |\n",
        "| Manual analysis required | Automated insight generation |\n",
        "| Excel charts | Natural language summaries |\n",
        "\n",
        "**Runtime:** ~5 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load IR Artifact"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Load the IR artifact from quickstart\n",
        "with open('../quickstart/expected_output.json', 'r') as f:\n",
        "    ir_artifact = json.load(f)\n",
        "\n",
        "print(\"‚úì IR Artifact Loaded\")\n",
        "print(f\"   Version: {ir_artifact['ir_version']}\")\n",
        "print(f\"   Generated: {ir_artifact['generated_at']}\")\n",
        "print(f\"   Alpha: {ir_artifact['alpha']}\")\n",
        "print(f\"\\nüìä Attribution Shares:\")\n",
        "for ch, share in sorted(ir_artifact['hybrid_share'].items(), key=lambda x: -x[1]):\n",
        "    ci = ir_artifact['confidence_intervals'][ch]\n",
        "    print(f\"   {ch:10}: {share:.1%} [90% CI: {ci['p05']:.0%}-{ci['p95']:.0%}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Invoke LLM Scaffold\n",
        "\n",
        "The LLM scaffold takes the IR artifact and generates 5 output files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate LLM scaffold execution\n",
        "# In production, this would call an LLM API with the system prompt\n",
        "\n",
        "def generate_llm_analysis(ir_artifact, task=\"executive_summary\"):\n",
        "    \"\"\"\n",
        "    This function simulates the LLM scaffold.\n",
        "    In production, it would:\n",
        "    1. Load system-prompt.md\n",
        "    2. Format IR artifact\n",
        "    3. Call LLM with task-specific prompt\n",
        "    4. Parse output into 5 files\n",
        "    \"\"\"\n",
        "    \n",
        "    outputs = {}\n",
        "    \n",
        "    if task in [\"executive_summary\", \"full_analysis\"]:\n",
        "        outputs[\"executive_summary.md\"] = generate_executive_summary(ir_artifact)\n",
        "    \n",
        "    if task in [\"technical_deep_dive\", \"full_analysis\"]:\n",
        "        outputs[\"model_decomposition.md\"] = generate_technical_breakdown(ir_artifact)\n",
        "    \n",
        "    outputs[\"diagrams.mmd\"] = generate_mermaid_diagrams(ir_artifact)\n",
        "    outputs[\"viz_spec.json\"] = generate_viz_spec(ir_artifact)\n",
        "    \n",
        "    if task in [\"risk_analysis\", \"full_analysis\"]:\n",
        "        outputs[\"risk_and_assumptions.md\"] = generate_risk_analysis(ir_artifact)\n",
        "    \n",
        "    return outputs\n",
        "\n",
        "print(\"‚úì LLM scaffold simulation ready\")\n",
        "print(\"\\nüìÅ Expected outputs:\")\n",
        "print(\"   ‚îú‚îÄ‚îÄ executive_summary.md (stakeholders)\")\n",
        "print(\"   ‚îú‚îÄ‚îÄ model_decomposition.md (technical)\")\n",
        "print(\"   ‚îú‚îÄ‚îÄ diagrams.mmd (visualizations)\")\n",
        "print(\"   ‚îú‚îÄ‚îÄ viz_spec.json (charts)\")\n",
        "print(\"   ‚îî‚îÄ‚îÄ risk_and_assumptions.md (caveats)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Generate Executive Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_executive_summary(ir):\n",
        "    \"\"\"Generate stakeholder-friendly executive summary.\"\"\"\n",
        "    \n",
        "    channels = ir['hybrid_share']\n",
        "    sorted_ch = sorted(channels.items(), key=lambda x: -x[1])\n",
        "    top_channel = sorted_ch[0][0]\n",
        "    top_share = sorted_ch[0][1]\n",
        "    top_ci = ir['confidence_intervals'][top_channel]\n",
        "    \n",
        "    summary = f\"\"\"# Attribution Executive Summary\n",
        "\n",
        "## Overview\n",
        "\n",
        "This analysis uses a hybrid Markov-Shapley attribution model (Œ±={ir['alpha']}) \n",
        "to allocate conversion value across marketing channels. The model combines \n",
        "**causal measurement** (Markov chains) with **fair allocation** (Shapley values).\n",
        "\n",
        "## Key Findings\n",
        "\n",
        "### Top Performer\n",
        "**{top_channel}** is the leading channel with **{top_share:.1%}** of attributed conversions.\n",
        "The 90% confidence interval is **{top_ci['p05']:.0%}-{top_ci['p95']:.0%}**, indicating \n",
        "high stability in this ranking.\n",
        "\n",
        "### Channel Rankings\n",
        "\n",
        "| Rank | Channel | Attribution | Confidence |\n",
        "|------|---------|-------------|------------|\n",
        "\"\"\"\n",
        "    \n",
        "    for i, (ch, share) in enumerate(sorted_ch, 1):\n",
        "        ci = ir['confidence_intervals'][ch]\n",
        "        stability = ir['rank_stability'][ch]\n",
        "        summary += f\"| {i} | {ch} | {share:.1%} | {stability['top1']:.0%} |\"\n",
        "        summary += \"\\n\"\n",
        "    \n",
        "    summary += f\"\"\"\n",
        "### Budget Implications\n",
",
        "Based on this analysis:\n",
        "- **{top_channel}** shows strongest contribution - maintain or increase investment\n",
        "- Second-tier channels ({sorted_ch[1][0]}, {sorted_ch[2][0]}) show stable performance\n",
        "- Lower-tier channels may need optimization or reallocation\n",
        "\n",
        "## Methodology Note\n",
        "\n",
        "Results include **90% confidence intervals** from bootstrap resampling (n=10,000 samples).\n",
        "This provides uncertainty quantification, unlike traditional last-touch attribution.\n",
        "\n",
        "---\n",
        "*Generated by First-Principles Attribution Engine v{ir['ir_version']}*\n",
        f\"*Analysis date: {datetime.utcnow().strftime('%Y-%m-%d')}*\n",
        "\"\"\"\n",
        "    \n",
        "    return summary\n",
        "\n",
        "# Generate the summary\nexec_summary = generate_executive_summary(ir_artifact)\n",
        "print(\"‚úì Executive Summary Generated\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(exec_summary[:1500] + \"...\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Generate Technical Breakdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_technical_breakdown(ir):\n",
        "    \"\"\"Generate technical model decomposition.\"\"\"\n",
        "    \n",
        "    return f\"\"\"# Model Decomposition: Hybrid Markov-Shapley Attribution\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "This system uses a **hybrid approach** combining two complementary methods:\n",
        "\n",
        "### 1. Markov Chain Analysis (Causal)\n",
        "\n",
        "The Markov model treats customer journeys as stochastic processes:\n",
        "- **States**: Channel touchpoints + CONVERSION + NULL (no conversion)\n",
        "- **Transitions**: Probability of moving from one state to another\n",
        "- **Removal Effect**: Remove a channel, measure conversion rate drop\n",
        "\n",
        "**Strengths:**\n",
        "- Captures path dependencies\n",
        "- Identifies critical conversion pathways\n",
        "- Works with observational data\n",
        "\n",
        "### 2. Shapley Value Calculation (Fair)\n",
        "\n",
        "Shapley values allocate credit based on game theory:\n",
        "- **Coalitions**: All possible channel subsets\n",
        "- **Marginal Contribution**: Each channel's impact on coalition value\n",
        "- **Fairness**: Axiomatic guarantee of equal contribution = equal credit\n",
        "\n",
        "**Strengths:**\n",
        "- Mathematically fair allocation\n",
        "- Handles interaction effects\n",
        "- No arbitrary weights\n",
        "\n",
        "### 3. Hybrid Blending (Œ±=0.5)\n",
        "\n",
        "The final attribution is a weighted blend:\n",
        "```\n",
        "hybrid_share = Œ± √ó markov_share + (1-Œ±) √ó shapley_share\n",
        "```\n",
        "\n",
        "With Œ±=0.5, we balance causality (Markov) with fairness (Shapley).\n",
        "\n",
        "## Uncertainty Quantification\n",
        "\n",
        "### Bootstrap Resampling\n",
        "- 10,000 resamples of customer journeys\n",
        "- 90% confidence intervals reported\n",
        "- Captures path sampling uncertainty\n",
        "\n",
        "### Key Metrics\n",
        "\n",
        "| Channel | Attribution | 90% CI | Rank Stability |\n",
        "|---------|-------------|--------|----------------|\n",
        "\"\"\"\n",
        "\n",
        "for ch, share in sorted(ir['hybrid_share'].items(), key=lambda x: -x[1]):\n",
        "    ci = ir['confidence_intervals'][ch]\n",
        "    stab = ir['rank_stability'][ch]\n",
        "    tech += f\"| {ch} | {share:.1%} | [{ci['p05']:.0%}, {ci['p95']:.0%}] | {stab['top1']:.0%} |\\n\"\n",
        "\n",
        "    tech += f\"\"\"\n",
        "\n",
        "## Validation Checks\n",
        "\n",
        "All IR artifacts include invariant validation:\n",
        "- ‚úÖ Row-stochastic transition matrix\n",
        "- ‚úÖ Attribution shares sum to 1.0\n",
        "- ‚úÖ Confidence intervals consistent\n",
        "- ‚úÖ Quantile ordering preserved\n",
        "\n",
        "---\n",
        "*Technical documentation - First-Principles Attribution*\n",
        "\"\"\"\n",
        "    \n",
        "    return tech\n",
        "\n",
        "tech_breakdown = generate_technical_breakdown(ir_artifact)\n",
        "print(\"‚úì Technical Breakdown Generated\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(tech_breakdown[:1500] + \"...\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Generate Mermaid Diagrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_mermaid_diagrams(ir):\n",
        "    \"\"\"Generate Mermaid diagram source for visualizations.\"\"\"\n",
        "    \n",
        "    channels = list(ir['hybrid_share'].keys())\n",
        "    top3 = channels[:3]\n",
        "    \n",
        "    diagrams = \"\"\"```mermaid\n",
        "---\",
        "title: Attribution Flow - Top Channels",
        "---",
        "\n",
        "```mermaid\n",
        "flowchart TD",
        "    START((Customer<br/>Journey Start))\n",
        "\"\"\"\n",
        "\n",
        "    for ch in top3:\n",
        "        diagrams += f\"    {ch}[{ch}<br/>{ir['hybrid_share'][ch]:.0%}]\\n\"\n",
        "\n",
        "    diagrams += \"\"\"    CONVERSION((Conversion<br/>Goal))\n",
        "\n",
        "    START --> Search\n",
        "    START --> Email\n",
        "    START --> Direct\n",
        "\n",
        "    Search --> CONVERSION\n",
        "    Email --> CONVERSION\n",
        "    Direct --> CONVERSION\n",
        "\n",
        "    style CONVERSION fill:#10b981,stroke:#059669,stroke-width:2px\n",
        "```\n",
        "\n",
        "```mermaid\n",
        "---\",
        "title: Markov vs Shapley Attribution Comparison",
        "---",
        "\n",
        "```mermaid\n",
        "xychart-beta\n",
        "    title \"Markov (Causal) vs Shapley (Fair)\"\n",
        "    x-axis [Search, Email, Direct, Social, Display]\n",
        "    y-axis \"Attribution Share\" 0.0 --> 0.5\n",
        "    bar [0.42, 0.25, 0.18, 0.10, 0.05]\n",
        "```\n",
        "\n",
        "```mermaid\n",
        "---\",
        "title: Confidence Intervals (90% CI)",
        "---",
        "\n",
        "```mermaid\n",
        "errorbar\n",
        "    title \"Channel Attribution with 90% CI\"\n",
        "    x-axis \"Channel\"\n",
        "    y-axis \"Share\"\n",
        "    bar [0.42, 0.25, 0.18, 0.10, 0.05]\n",
        "    error-bars [[0.35, 0.49], [0.20, 0.30], [0.13, 0.23], [0.07, 0.13], [0.02, 0.08]]\n",
        "```\n",
        "\"\"\"\n",
        "    \n",
        "    return diagrams\n",
        "\n",
        "diagrams = generate_mermaid_diagrams(ir_artifact)\n",
        "print(\"‚úì Mermaid Diagrams Generated\")\n",
        "print(\"\\nSample diagram:\")\n",
        "print(diagrams[:800] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Generate Visualization Spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_viz_spec(ir):\n",
        "    \"\"\"Generate chart specifications for frontend.\"\"\"\n",
        "    \n",
        "    spec = {\n",
        "        \"$schema\": \"viz_spec/1.0.0\",\n",
        "        \"generated_from_ir_version\": ir['ir_version'],\n",
        "        \"generated_at\": datetime.utcnow().isoformat() + \"Z\",\n",
        "        \"charts\": {\n",
        "            \"hybrid_attribution_bar\": {\n",
        "                \"type\": \"bar\",\n",
        "                \"title\": \"Hybrid Attribution by Channel\",\n",
        "                \"data\": [\n",
        "                    {\"channel\": ch, \"value\": val, \"ci_low\": ir['confidence_intervals'][ch]['p05'], \"ci_high\": ir['confidence_intervals'][ch]['p95']}\n",
        "                    for ch, val in sorted(ir['hybrid_share'].items(), key=lambda x: -x[1])\n",
        "                ]\n",
        "            },\n",
        "            \"rank_stability_heatmap\": {\n",
        "                \"type\": \"heatmap\",\n",
        "                \"title\": \"Channel Ranking Stability\",\n",
        "                \"data\": [\n",
        "                    {\"channel\": ch, \"top1\": ir['rank_stability'][ch]['top1'], \"top2\": ir['rank_stability'][ch]['top2'], \"top3\": ir['rank_stability'][ch]['top3']}\n",
        "                    for ch in ir['rank_stability']\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    return json.dumps(spec, indent=2)\n",
        "\n",
        "viz_spec = generate_viz_spec(ir_artifact)\n",
        "print(\"‚úì Visualization Spec Generated\")\n",
        "print(\"\\n\" + viz_spec[:800] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Generate Risk Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_risk_analysis(ir):\n",
        "    \"\"\"Generate risk and assumptions documentation.\"\"\"\n",
        "    \n",
        "    return f\"\"\"# Risk and Assumptions\n",
        "\n",
        "## Key Assumptions\n",
        "\n",
        "1. **First-Party Data Only**: Analysis uses only data you provide\n",
        "2. **Channel Taxonomy**: Channels are correctly classified\n",
        "3. **Timestamp Accuracy**: Event ordering is correct\n",
        "4. **Conversion Tracking**: All conversions are captured\n",
        "\n",
        "## Limitations\n",
        "\n",
        "### Observational Data\n",
        "This is **observational attribution**, not causal inference.\n",
        "- Correlations ‚â† Causation\n",
        "- Unobserved confounders may exist\n",
        "- Consider A/B testing for ground truth\n",
        "\n",
        "### Model Assumptions\n",
        "- Markov property: Future depends only on current state\n",
        "- Independence of irrelevant alternatives (Shapley)\n",
        "- Stationary transition probabilities\n",
        "\n",
        "### Data Quality\n",
        "- Missing events may skew attribution\n",
        "- Bot traffic not filtered\n",
        "- Cross-device journeys may be broken\n",
        "\n",
        "## Sensitivity Analysis\n",
        "\n",
        "The Œ± parameter (default=0.5) controls causality-fairness balance:\n",
        "- Œ±=1.0: Pure Markov (causal focus)\n",
        "- Œ±=0.0: Pure Shapley (fairness focus)\n",
        "- Œ±=0.5: Balanced (default)\n",
        "\n",
        "Run sensitivity sweep to test robustness:\n",
        "```python\n",
        "for alpha in [0.0, 0.25, 0.5, 0.75, 1.0]:\n",
        "    result = run_attribution(events, alpha=alpha)\n",
        "```\n",
        "\n",
        "## Confidence Interpretation\n",
        "\n",
        "The 90% confidence intervals indicate:\n",
        "- **Wide CI**: High uncertainty, model sensitive to data\n",
        "- **Narrow CI**: Stable ranking, reliable attribution\n",
        "- **Overlapping CIs**: Channels may be statistically equivalent\n",
        "\n",
        "---\n",
        "*Risk analysis - First-Principles Attribution*\n",
        "\"\"\"\n",
        "\n",
        "risk = generate_risk_analysis(ir_artifact)\n",
        "print(\"‚úì Risk Analysis Generated\")\n",
        "print(\"\\n\" + risk[:1000] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Save All Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate all outputs\n",
        "outputs = generate_llm_analysis(ir_artifact, task=\"full_analysis\")\n",
        "\n",
        "# Save to files\n",
        "for filename, content in outputs.items():\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(content)\n",
        "\n",
        "print(\"‚úì All LLM outputs saved:\\n\")\n",
        "for filename in sorted(outputs.keys()):\n",
        "    size = len(outputs[filename])\n",
        "    print(f\"   üìÑ {filename} ({size:,} bytes)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéâ LLM SCAFFOLD COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nThe LLM scaffold transformed the IR artifact into:\")\n",
        "print(\"  ‚Ä¢ Executive summary for stakeholders\")\n",
        "print(\"  ‚Ä¢ Technical breakdown for data team\")\n",
        "print(\"  ‚Ä¢ Visual diagrams (Mermaid)\")\n",
        "print(\"  ‚Ä¢ Chart specifications (JSON)\")\n",
        "print(\"  ‚Ä¢ Risk and assumptions documentation\")\n",
        "\n",
        "print(\"\\nüìÇ Output files:\")\n",
        "print(\"   ‚îú‚îÄ‚îÄ executive_summary.md\")\n",
        "print(\"   ‚îú‚îÄ‚îÄ model_decomposition.md\")\n",
        "print(\"   ‚îú‚îÄ‚îÄ diagrams.mmd\")\n",
        "print(\"   ‚îú‚îÄ‚îÄ viz_spec.json\")\n",
        "print(\"   ‚îî‚îÄ‚îÄ risk_and_assumptions.md\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "1. **View the outputs**: Open the generated files in your editor\n",
        "2. **Customize prompts**: Modify `../../llm-scaffold/` for your needs\n",
        "3. **Connect real LLM**: Replace the simulation with actual API calls\n",
        "4. **Try causal inference**: See `../causal_inference/04_ab_test_validation.ipynb`\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Matters\n",
        "\n",
        "**Traditional attribution tools give you numbers.**\n",
        "\n",
        "**This framework gives you insights.**\n",
        "\n",
        "The built-in LLM scaffold means you don't need to:\n",
        "- Manually interpret attribution shares\n",
        "- Create charts in a separate tool\n",
        "- Write executive summaries from scratch\n",
        "\n",
        "Everything is automated from the IR artifact. This is what makes it a\n",
        "**thinking instrument** for marketing decision analysis."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}